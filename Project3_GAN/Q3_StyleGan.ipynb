{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "Copy of Copy of t81_558_class_07_3_style_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.7 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ac7baca314b4f2d973917abff2df8b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ff5f90e5c6f4d4b8fb01bf19308bd80",
              "IPY_MODEL_8e9b32e4c8b5403f855d7c05b34fea41"
            ],
            "layout": "IPY_MODEL_ae2f30c30761451b82eb845d60ca9b41"
          }
        },
        "ae2f30c30761451b82eb845d60ca9b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ff5f90e5c6f4d4b8fb01bf19308bd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Seed 1000: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3c5308b14574720b9df4020a72e6b6d",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3aa92c5cb3b64b70b8d5f23c6acab7f0",
            "value": 100
          }
        },
        "8e9b32e4c8b5403f855d7c05b34fea41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e6a35c901d74356ab83eb804aee2a8e",
            "placeholder": "​",
            "style": "IPY_MODEL_1192f40ad89b4a22984a36a1a4d3e32f",
            "value": " 100/100 [13:55&lt;00:00,  8.35s/it]"
          }
        },
        "3aa92c5cb3b64b70b8d5f23c6acab7f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "b3c5308b14574720b9df4020a72e6b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1192f40ad89b4a22984a36a1a4d3e32f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e6a35c901d74356ab83eb804aee2a8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dabdfe32a3e649ae9291870438539651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a568ce9f9397422c8c9e910a384dd47e",
              "IPY_MODEL_7027e2ca4cb24c02b43f36cdecde3716"
            ],
            "layout": "IPY_MODEL_a8df5a99532349bb8509415fc1b1c9c2"
          }
        },
        "a8df5a99532349bb8509415fc1b1c9c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a568ce9f9397422c8c9e910a384dd47e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Seed 1003: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0fe4401f5534b11b6b39d4293fb92e0",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edfd67d6bc4445a680256dc258b7904e",
            "value": 100
          }
        },
        "7027e2ca4cb24c02b43f36cdecde3716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6ffff6587fd4291a14d1a3642e5be67",
            "placeholder": "​",
            "style": "IPY_MODEL_336b034007324ed490d1793cf4a6187b",
            "value": " 100/100 [13:00&lt;00:00,  7.81s/it]"
          }
        },
        "edfd67d6bc4445a680256dc258b7904e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "e0fe4401f5534b11b6b39d4293fb92e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "336b034007324ed490d1793cf4a6187b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6ffff6587fd4291a14d1a3642e5be67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVXeD0a16Q9D"
      },
      "source": [
        "# Mini Project3 - Question 3 - StyleGAN\n",
        "## Mahsa Massoid - Omid Vaheb \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv7PBBU7kOkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35da14b0-1c34-4abc-80a1-9d54e26363ea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0rmyrNu6KXy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB0TryzptCf_",
        "outputId": "5b38fbce-fe6a-4560-99ef-c87285c3ee88"
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n",
        "!pip install ninja"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stylegan2-ada-pytorch'...\n",
            "remote: Enumerating objects: 125, done.\u001b[K\n",
            "remote: Total 125 (delta 0), reused 0 (delta 0), pack-reused 125\u001b[K\n",
            "Receiving objects: 100% (125/125), 1.12 MiB | 13.67 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n",
            "Collecting ninja\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/de/393468f2a37fc2c1dc3a06afc37775e27fde2d16845424141d4da62c686d/ninja-1.10.0.post2-py3-none-manylinux1_x86_64.whl (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 13.7MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.0.post2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wewBEme5tCgD",
        "outputId": "3bcd1bb8-b86e-4067-bdd8-be09726d28f9"
      },
      "source": [
        "!ls /content/stylegan2-ada-pytorch/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calc_metrics.py  docker_run.sh\tLICENSE.txt   style_mixing.py\n",
            "dataset_tool.py  docs\t\tmetrics       torch_utils\n",
            "dnnlib\t\t generate.py\tprojector.py  training\n",
            "Dockerfile\t legacy.py\tREADME.md     train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQGFXRI0tCgG"
      },
      "source": [
        "## Run StyleGan2 From Command Line\n",
        "Add the StyleGAN folder to Python so that you can import it.  The code below is based on code from NVidia. This actually generates your images. When you use StyleGAN you will generally create a GAN from a seed number, such as 6600.  GANs are actually created by a latent vector, containing 512 floating point values.  The seed is used by the GAN code to generate these 512 values.  The seed value is easier to represent in code than a 512 value vector.  However, while a small change to the latent vector results in a small change to the image, even a small change to the seed value will produce a radically different image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn_lpC_p-4ag",
        "outputId": "c9cf2277-b242-4db0-d6e0-05748aab45a3"
      },
      "source": [
        "!python /content/stylegan2-ada-pytorch/generate.py \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl \\\n",
        "  --outdir=/content/results --seeds=6600-6625 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl\"...\n",
            "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl ... done\n",
            "Generating image for seed 6600 (0/26) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Generating image for seed 6601 (1/26) ...\n",
            "Generating image for seed 6602 (2/26) ...\n",
            "Generating image for seed 6603 (3/26) ...\n",
            "Generating image for seed 6604 (4/26) ...\n",
            "Generating image for seed 6605 (5/26) ...\n",
            "Generating image for seed 6606 (6/26) ...\n",
            "Generating image for seed 6607 (7/26) ...\n",
            "Generating image for seed 6608 (8/26) ...\n",
            "Generating image for seed 6609 (9/26) ...\n",
            "Generating image for seed 6610 (10/26) ...\n",
            "Generating image for seed 6611 (11/26) ...\n",
            "Generating image for seed 6612 (12/26) ...\n",
            "Generating image for seed 6613 (13/26) ...\n",
            "Generating image for seed 6614 (14/26) ...\n",
            "Generating image for seed 6615 (15/26) ...\n",
            "Generating image for seed 6616 (16/26) ...\n",
            "Generating image for seed 6617 (17/26) ...\n",
            "Generating image for seed 6618 (18/26) ...\n",
            "Generating image for seed 6619 (19/26) ...\n",
            "Generating image for seed 6620 (20/26) ...\n",
            "Generating image for seed 6621 (21/26) ...\n",
            "Generating image for seed 6622 (22/26) ...\n",
            "Generating image for seed 6623 (23/26) ...\n",
            "Generating image for seed 6624 (24/26) ...\n",
            "Generating image for seed 6625 (25/26) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnrUF5L1_3UI",
        "outputId": "b8f7db76-b1cb-4249-e976-255c7ceec01f"
      },
      "source": [
        "!ls /content/results/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seed6600.png  seed6606.png  seed6612.png  seed6618.png\tseed6624.png\n",
            "seed6601.png  seed6607.png  seed6613.png  seed6619.png\tseed6625.png\n",
            "seed6602.png  seed6608.png  seed6614.png  seed6620.png\n",
            "seed6603.png  seed6609.png  seed6615.png  seed6621.png\n",
            "seed6604.png  seed6610.png  seed6616.png  seed6622.png\n",
            "seed6605.png  seed6611.png  seed6617.png  seed6623.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeUdlQkINRI5"
      },
      "source": [
        "Next, copy the images to a folder of your choice on GDrive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rh5faG6AOFA"
      },
      "source": [
        "cp /content/results/* \\\n",
        "    /content/drive/My\\ Drive/projects/stylegan2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D92Md-Hw3eVA"
      },
      "source": [
        "## Run StyleGAN2 From Python Code\n",
        "\n",
        "Add the StyleGAN2 folder to Python so that you can import it.  The code below is based on code from NVIDIA. This actually generates your images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgMm1sSutCgH"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/stylegan2-ada-pytorch\")\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display\n",
        "import torch\n",
        "import dnnlib\n",
        "import legacy\n",
        "\n",
        "def seed2vec(G, seed):\n",
        "  return np.random.RandomState(seed).randn(1, G.z_dim)\n",
        "\n",
        "def display_image(image):\n",
        "  plt.axis('off')\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "\n",
        "def generate_image(G, z, truncation_psi):\n",
        "    # Render images for dlatents initialized from random seeds.\n",
        "    Gs_kwargs = {\n",
        "        'output_transform': dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True),\n",
        "        'randomize_noise': False\n",
        "    }\n",
        "    if truncation_psi is not None:\n",
        "        Gs_kwargs['truncation_psi'] = truncation_psi\n",
        "\n",
        "    label = np.zeros([1] + G.input_shapes[1][1:])\n",
        "    images = G.run(z, label, **G_kwargs) # [minibatch, height, width, channel]\n",
        "    return images[0]\n",
        "\n",
        "def get_label(G, device, class_idx):\n",
        "  label = torch.zeros([1, G.c_dim], device=device)\n",
        "  if G.c_dim != 0:\n",
        "      if class_idx is None:\n",
        "          ctx.fail('Must specify class label with --class when using a conditional network')\n",
        "      label[:, class_idx] = 1\n",
        "  else:\n",
        "      if class_idx is not None:\n",
        "          print ('warn: --class=lbl ignored when running on an unconditional network')\n",
        "  return label\n",
        "\n",
        "def generate_image(device, G, z, truncation_psi=1.0, noise_mode='const', class_idx=None):\n",
        "  z = torch.from_numpy(z).to(device)\n",
        "  label = get_label(G, device, class_idx)\n",
        "  img = G(z, label, truncation_psi=truncation_psi, noise_mode=noise_mode)\n",
        "  img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "  #PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{outdir}/seed{seed:04d}.png')\n",
        "  return PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjBnVUXtRhqN",
        "outputId": "f3e63411-dca1-4031-c15b-b825b2414439"
      },
      "source": [
        "URL = \"https://github.com/jeffheaton/pretrained-gan-fish/releases/download/1.0.0/fish-gan-2020-12-09.pkl\"\n",
        "#URL = \"https://github.com/jeffheaton/pretrained-merry-gan-mas/releases/download/v1/christmas-gan-2020-12-03.pkl\"\n",
        "#URL = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl\"\n",
        "#URL = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"\n",
        "\n",
        "print(f'Loading networks from \"{URL}\"...')\n",
        "device = torch.device('cuda')\n",
        "with dnnlib.util.open_url(URL) as f:\n",
        "    G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading networks from \"https://github.com/jeffheaton/pretrained-gan-fish/releases/download/1.0.0/fish-gan-2020-12-09.pkl\"...\n",
            "Downloading https://github.com/jeffheaton/pretrained-gan-fish/releases/download/1.0.0/fish-gan-2020-12-09.pkl ... done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78DnfkBhR5W6"
      },
      "source": [
        "# Choose your own starting and ending seed.\n",
        "SEED_FROM = 1000\n",
        "SEED_TO = 1003\n",
        "\n",
        "# Generate the images for the seeds.\n",
        "for i in range(SEED_FROM, SEED_TO):\n",
        "  print(f\"Seed {i}\")\n",
        "  z = seed2vec(G, i)\n",
        "  img = generate_image(device, G, z)\n",
        "  display_image(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jJ8prvsy3am",
        "outputId": "15d33ee3-15a2-4f0b-ed01-e0265eb92abb"
      },
      "source": [
        "def expand_seed(seeds, vector_size):\n",
        "  result = []\n",
        "\n",
        "  for seed in seeds:\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    result.append( rnd.randn(1, vector_size) ) \n",
        "  return result\n",
        "\n",
        "#URL = \"https://github.com/jeffheaton/pretrained-gan-fish/releases/download/1.0.0/fish-gan-2020-12-09.pkl\"\n",
        "#URL = \"https://github.com/jeffheaton/pretrained-merry-gan-mas/releases/download/v1/christmas-gan-2020-12-03.pkl\"\n",
        "URL = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl\"\n",
        "\n",
        "print(f'Loading networks from \"{URL}\"...')\n",
        "device = torch.device('cuda')\n",
        "with dnnlib.util.open_url(URL) as f:\n",
        "    G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore\n",
        "\n",
        "vector_size = G.z_dim\n",
        "# range(8192,8300)\n",
        "seeds = expand_seed( [8192+1,8192+9], vector_size)\n",
        "#generate_images(Gs, seeds,truncation_psi=0.5)\n",
        "print(seeds[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl\"...\n",
            "(1, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty-ou1_zjKqs"
      },
      "source": [
        "The following code will move between the provided seeds.  The constant STEPS specify how many frames there should be between each of the seeds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611,
          "referenced_widgets": [
            "3ac7baca314b4f2d973917abff2df8b5",
            "ae2f30c30761451b82eb845d60ca9b41",
            "2ff5f90e5c6f4d4b8fb01bf19308bd80",
            "8e9b32e4c8b5403f855d7c05b34fea41",
            "3aa92c5cb3b64b70b8d5f23c6acab7f0",
            "b3c5308b14574720b9df4020a72e6b6d",
            "1192f40ad89b4a22984a36a1a4d3e32f",
            "3e6a35c901d74356ab83eb804aee2a8e",
            "dabdfe32a3e649ae9291870438539651",
            "a8df5a99532349bb8509415fc1b1c9c2",
            "a568ce9f9397422c8c9e910a384dd47e",
            "7027e2ca4cb24c02b43f36cdecde3716",
            "edfd67d6bc4445a680256dc258b7904e",
            "e0fe4401f5534b11b6b39d4293fb92e0",
            "336b034007324ed490d1793cf4a6187b",
            "f6ffff6587fd4291a14d1a3642e5be67"
          ]
        },
        "id": "VLI6T_8ZVqMJ",
        "outputId": "757b6470-1825-4e04-f6cd-8453908f078c"
      },
      "source": [
        "# Choose your seeds to morph through and the number of steps to take to get to each.\n",
        "\n",
        "SEEDS = [1000,1003,1001]\n",
        "STEPS = 100\n",
        "\n",
        "# Remove any prior results\n",
        "!rm /content/results/* \n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "os.makedirs(\"./results/\", exist_ok=True)\n",
        "\n",
        "# Generate the images for the video.\n",
        "idx = 0\n",
        "for i in range(len(SEEDS)-1):\n",
        "  v1 = seed2vec(G, SEEDS[i])\n",
        "  v2 = seed2vec(G, SEEDS[i+1])\n",
        "\n",
        "  diff = v2 - v1\n",
        "  step = diff / STEPS\n",
        "  current = v1.copy()\n",
        "\n",
        "  for j in tqdm(range(STEPS), desc=f\"Seed {SEEDS[i]}\"):\n",
        "    current = current + step\n",
        "    img = generate_image(device, G, current)\n",
        "    img.save(f'./results/frame-{idx}.png')\n",
        "    idx+=1\n",
        " \n",
        "# Link the images into a video.\n",
        "!ffmpeg -r 30 -i /content/results/frame-%d.png -vcodec mpeg4 -y movie.mp4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ac7baca314b4f2d973917abff2df8b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Seed 1000', style=ProgressStyle(description_width='initia…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dabdfe32a3e649ae9291870438539651",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Seed 1003', style=ProgressStyle(description_width='initia…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2, from '/content/results/frame-%d.png':\n",
            "  Duration: 00:00:08.00, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 1024x1024, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (png (native) -> mpeg4 (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp4, to 'movie.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: mpeg4 (mp4v / 0x7634706D), yuv420p, 1024x1024, q=2-31, 200 kb/s, 30 fps, 15360 tbn, 30 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 mpeg4\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
            "frame=  200 fps= 45 q=31.0 Lsize=    1417kB time=00:00:06.63 bitrate=1750.3kbits/s speed=1.49x    \n",
            "video:1416kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.120174%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPO-aKnY9O4P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX4LsOo_YstE"
      },
      "source": [
        "Next, clone Stylegan from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjDcs9Wvhk_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee2aeb5-e311-4a10-83da-5c9a6ea1046b"
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stylegan'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Total 86 (delta 0), reused 0 (delta 0), pack-reused 86\u001b[K\n",
            "Unpacking objects: 100% (86/86), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhGqVIl8Y1m1"
      },
      "source": [
        "Verify that Stylegan has been cloned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TQMXLBNjoV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e014e849-53d2-4ec8-df41-4868caa3ecf9"
      },
      "source": [
        "!ls /content/stylegan/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "config.py\t     LICENSE.txt\t    run_metrics.py\n",
            "dataset_tool.py      metrics\t\t    stylegan-teaser.png\n",
            "dnnlib\t\t     pretrained_example.py  training\n",
            "generate_figures.py  README.md\t\t    train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zARjPp4rY6vc"
      },
      "source": [
        "Add the Stylegan folder to Python so that you can import it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaFXI2RMhmly"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/stylegan\")\n",
        "\n",
        "import dnnlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxmjqpxdZFkj"
      },
      "source": [
        "The code below is baed on code from NVidia.  This actually generates your images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfN_qgXVi2PU"
      },
      "source": [
        "\n",
        "# Generating Random Images From Style-GAN:\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "!pip install tensorflow==1.15.0\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config\n",
        "\n",
        "def main():\n",
        "    # Initialize TensorFlow.\n",
        "    tflib.init_tf()\n",
        "\n",
        "    # Load pre-trained network.\n",
        "    url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl\n",
        "    with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
        "        _G, _D, Gs = pickle.load(f)\n",
        "        # _G = Instantaneous snapshot of the generator. Mainly useful for resuming a previous training run.\n",
        "        # _D = Instantaneous snapshot of the discriminator. Mainly useful for resuming a previous training run.\n",
        "        # Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.\n",
        "\n",
        "    # Print network details.\n",
        "    Gs.print_layers()\n",
        "\n",
        "    # Pick latent vector.\n",
        "    rnd = np.random.RandomState(42)\n",
        "    \n",
        "\n",
        "    latents = rnd.randn(1, Gs.input_shape[1])\n",
        "\n",
        "    # Generate image.\n",
        "    fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)\n",
        "\n",
        "    # Save image.\n",
        "    os.makedirs(config.result_dir, exist_ok=True)\n",
        "    png_filename = os.path.join(config.result_dir, f'/content/drive/My Drive/images/example.png')\n",
        "    PIL.Image.fromarray(images[0], 'RGB').save(png_filename)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzqJGX1Gj_fn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3571eecf-fa70-426b-f65a-136c9a39196e"
      },
      "source": [
        "!ls /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Colab Notebooks'\t\t\t\t  example.png\n",
            "'Copy of karras2019stylegan-ffhq-1024x1024.pkl'   projects\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}